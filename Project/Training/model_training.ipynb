{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK7qmOlkZosj"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle as shuffle_dataframe\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJiCSsHfPc--"
      },
      "outputs": [],
      "source": [
        "# From sensorlogger generated csv to pandas dataframe for training/testing ADL instance generation\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
        "    nyquist = 0.5 * fs  # Nyquist frequency\n",
        "    normal_cutoff = cutoff / nyquist  # Normalize cutoff frequency\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)  # Filter coefficients\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def sensorLoggerCSVtoADLDatasetDF(sensorLoggerCSV, hardCodedLabel=0):\n",
        "    pd_accel = pd.read_csv(sensorLoggerCSV)\n",
        "    magList = np.sqrt(pd_accel[\"x\"]**2 + pd_accel[\"y\"]**2 + pd_accel[\"z\"]**2)\n",
        "    cutoff_frequency = 5  # 5 hz cutoff frequency\n",
        "    sampling_frequency = 100  # Sampling frequency (set to same in SensorLogger app)\n",
        "    filtered_magnitude = butter_lowpass_filter(magList, cutoff_frequency, sampling_frequency)\n",
        "    magList = filtered_magnitude\n",
        "    newDF = pd.DataFrame(columns=['magnitude', 'label'])\n",
        "    for i in range(int(np.floor(len(magList)/350)) -1): # Mimic the overlapping buffers at server side\n",
        "        new_row = pd.DataFrame([{'label': hardCodedLabel, 'magnitude': magList[i*350:(i+2)*350]}])\n",
        "        newDF = pd.concat([newDF, new_row], ignore_index=True)\n",
        "    return newDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDrHGqklPuxT"
      },
      "outputs": [],
      "source": [
        "# collective dataframe's adl data\n",
        "\n",
        "# ADL csv #1\n",
        "df_all_adl1 = sensorLoggerCSVtoADLDatasetDF(\"ADHL.csv\", 0)\n",
        "# ADL csv #2\n",
        "df_all_adl2 = sensorLoggerCSVtoADLDatasetDF(\"fenste_cesitli_adl.csv\", 0)\n",
        "\n",
        "# grouped\n",
        "df_all_adl = pd.concat([df_all_adl1, df_all_adl2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtP3z2i0QH8Y",
        "outputId": "981334a1-8aaa-496b-b14f-cd8e401b56ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           magnitude label\n",
            "0  [0.10862444767918161, 0.12015273550077053, 0.1...     0\n",
            "1  [1.444881831370672, 1.400732918822068, 1.36796...     0\n",
            "2  [3.3084275101015432, 3.333994796347804, 3.3400...     0\n",
            "3  [1.6737453314664086, 1.549882802317406, 1.4348...     0\n",
            "4  [1.4447371474180417, 1.4496534504870808, 1.446...     0\n",
            "(677, 2) 700\n"
          ]
        }
      ],
      "source": [
        "# Check data format\n",
        "print(df_all_adl.head()) # magnitude and label, length = 677\n",
        "print(df_all_adl.shape, len(df_all_adl['magnitude'][17])) # randomly selected 17th instance for checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rNkY12Wb9fa",
        "outputId": "340931f0-b791-4cb5-c944-4bfcc4c053e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ],
      "source": [
        "#Check types, should be numpy array\n",
        "\n",
        "#print(type(df_all_adl['magnitude'][17])) # type = numpy.ndarray\n",
        "#print(type(df_all_adl['magnitude'][17][24])) # type = numpy.float64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WkvPxsFRLsJ"
      },
      "outputs": [],
      "source": [
        "## From sensorlogger generated csv to pandas dataframe for training/testing Fall instance generation\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
        "    nyquist = 0.5 * fs  # Nyquist frequency\n",
        "    normal_cutoff = cutoff / nyquist  # Normalize cutoff frequency\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)  # Filter coefficients\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def ZiptoSensorLoggerCSVtoFallDatasetDF(zip_file_path, label):\n",
        "    \"\"\"\n",
        "    Parse CSV files in a zip archive, compute filtered magnitudes, and return a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - zip_file_path: Path to the zip file containing CSV files.\n",
        "    - label: A label to assign to each processed row in the output DataFrame.\n",
        "\n",
        "    Returns:\n",
        "    - A DataFrame with columns ['magnitude', 'label'].\n",
        "    \"\"\"\n",
        "    cutoff_frequency = 5\n",
        "    sampling_frequency = 100 # same in Sensor Logger app\n",
        "    final_df = pd.DataFrame(columns=[\"magnitude\", \"label\"])\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
        "        # Iterate over each file in the zip\n",
        "        for file_name in zf.namelist():\n",
        "            if file_name.endswith('.csv'):  # only process CSV files\n",
        "                with zf.open(file_name) as f:\n",
        "                    df = pd.read_csv(f)\n",
        "                    # Compute magnitude\n",
        "                    mag_list = np.sqrt(df[\"x\"][:700]**2 + df[\"y\"][:700]**2 + df[\"z\"][:700]**2)\n",
        "\n",
        "                    if len(mag_list) != 700:  # some frames may not have arrived as 700, but longer\n",
        "                        print(f\"Skipping file {file_name} due to length mismatch.\")\n",
        "                        continue\n",
        "\n",
        "                    filtered_magnitude = butter_lowpass_filter(mag_list,\n",
        "                                                               cutoff_frequency,\n",
        "                                                               sampling_frequency)\n",
        "\n",
        "                    # Ensure magnitude is stored as a NumPy array of np.float64\n",
        "                    filtered_magnitude = np.array(filtered_magnitude, dtype=np.float64)\n",
        "\n",
        "                    # Add a row to the final DataFrame\n",
        "                    final_df = pd.concat([final_df, pd.DataFrame({\n",
        "                        \"magnitude\": [filtered_magnitude],  # Store as ndarray\n",
        "                        \"label\": [label]\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "    return final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ479qksaMBd"
      },
      "outputs": [],
      "source": [
        "# collective dataframe's fall data\n",
        "df_all_fall = ZiptoSensorLoggerCSVtoFallDatasetDF(\"fall.zip\", 1) # 1 is the class of Fall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "350-pKieaalM",
        "outputId": "daf10846-fc32-44e5-a18a-125a7af4dd92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           magnitude label\n",
            "0  [0.5328667607151071, 0.5195322355717552, 0.505...     1\n",
            "1  [1.5904970367859106, 1.8890880248191795, 2.181...     1\n",
            "2  [2.8853236893637364, 4.322460662583523, 5.7606...     1\n",
            "3  [1.842108267908963, 1.7704485758638333, 1.7088...     1\n",
            "4  [1.2664707778494908, 1.181644630166627, 1.0997...     1\n",
            "(252, 2) 700\n"
          ]
        }
      ],
      "source": [
        "# # Check data format\n",
        "print(df_all_fall.head()) # magnitude and label, length = 252\n",
        "print(df_all_fall.shape, len(df_all_fall['magnitude'][17])) # randomly selected 17 for checking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQfNLOx4cLsM",
        "outputId": "31164258-0643-4193-c4a6-7997a296388f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ],
      "source": [
        "# Check the types, should be numpy array\n",
        "#print(type(df_all_fall['magnitude'][17])) # type = numpy.ndarray\n",
        "#print(type(df_all_fall['magnitude'][17][24])) # type = numpy.float64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tCDVCr6a0GG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "in total, we have\n",
        "\n",
        "* 677 non-fall frames\n",
        "\n",
        "* 252 fall frames\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVmELiYUbOez"
      },
      "outputs": [],
      "source": [
        "# partition into train(75%) and test(25%), and save each as csv for checkpoint saving\n",
        "\n",
        "def split_and_concatenate(df_0, df_1, split_ratio=0.8, random_state=None, shuffle=True):\n",
        "    \"\"\"\n",
        "    Splits two dataframes into train and test sets, concatenates the respective train and test sets,\n",
        "    and returns the concatenated dataframes.\n",
        "\n",
        "    Parameters:\n",
        "    - df_0, df_1: DataFrames with \"magnitude\" and \"label\" columns.\n",
        "    - split_ratio: Fraction of data to use for training (default is 0.8).\n",
        "    - random_state: Seed for reproducibility (default is None).\n",
        "    - shuffle: Whether to shuffle the data before splitting (default is True).\n",
        "\n",
        "    Returns:\n",
        "    - concatenated_train: DataFrame containing the concatenated training data.\n",
        "    - concatenated_test: DataFrame containing the concatenated testing data.\n",
        "    \"\"\"\n",
        "    # Split dataframe_0\n",
        "    train_0, test_0 = train_test_split(df_0, train_size=split_ratio, random_state=random_state, shuffle=shuffle)\n",
        "\n",
        "    # Split dataframe_1\n",
        "    train_1, test_1 = train_test_split(df_1, train_size=split_ratio, random_state=random_state, shuffle=shuffle)\n",
        "\n",
        "    # Concatenate the train and test sets from both dataframes\n",
        "    concatenated_train = pd.concat([train_0, train_1], ignore_index=True)\n",
        "    concatenated_test = pd.concat([test_0, test_1], ignore_index=True)\n",
        "\n",
        "    # this way, ratio of fall in the training and testing is preserved\n",
        "    concatenated_train = shuffle_dataframe(concatenated_train, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "    return concatenated_train, concatenated_test\n",
        "\n",
        "\n",
        "df_train, df_test = split_and_concatenate(df_all_fall, df_all_adl, split_ratio=0.75, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXat6y5EnduG",
        "outputId": "f8edf704-f3ff-4c4d-ecdc-be34951fec97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             magnitude label\n",
            "0    [0.1326578051724844, 0.13283962244896616, 0.13...     0\n",
            "1    [0.6083756484766984, 0.5905265785234092, 0.569...     0\n",
            "2    [1.8035385855709463, 1.7782845838195986, 1.749...     0\n",
            "3    [0.14354524599307067, 0.14884563015451394, 0.1...     0\n",
            "4    [4.991880381135296, 5.164283039646422, 5.34169...     0\n",
            "..                                                 ...   ...\n",
            "691  [0.9083248511243021, 0.8580184370042581, 0.805...     1\n",
            "692  [2.3426368375036732, 2.1251324920545858, 1.919...     1\n",
            "693  [2.911069284341918, 3.114591253513609, 3.28247...     0\n",
            "694  [0.1823601147091017, 0.18215057287687006, 0.18...     0\n",
            "695  [3.221259909226104, 2.8945660093702137, 2.5765...     1\n",
            "\n",
            "[696 rows x 2 columns]\n",
            "                                             magnitude label\n",
            "0    [8.199972858164518, 7.80967043429824, 7.439945...     1\n",
            "1    [3.549445965355439, 3.147572596743873, 2.75440...     1\n",
            "2    [1.8778259878237888, 1.8701325224613146, 1.862...     1\n",
            "3    [1.7107833890019264, 2.2916978322167942, 2.852...     1\n",
            "4    [5.829500434999828, 5.890082211994131, 5.94709...     1\n",
            "..                                                 ...   ...\n",
            "228  [4.495366997974028, 4.605086770583731, 4.65004...     0\n",
            "229  [0.19278639725407284, 0.19037539412558963, 0.1...     0\n",
            "230  [3.304369267928538, 3.345879261241465, 3.36128...     0\n",
            "231  [1.242999132903103, 1.3059955623499835, 1.3478...     0\n",
            "232  [0.16038002003847834, 0.1603908742013376, 0.16...     0\n",
            "\n",
            "[233 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# check the dfs\n",
        "#print(df_train) # 696 rows\n",
        "#print(df_test) # 233 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El3oAJP_niYt"
      },
      "outputs": [],
      "source": [
        "# save the dataframes before training for easier access next time\n",
        "df_train.to_csv('df_train.csv', index=False)\n",
        "df_test.to_csv('df_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b7Y2PC38sPT",
        "outputId": "07beb41e-0ede-44f1-ae7d-82b5992f4760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ],
      "source": [
        "#print(type(df_train[\"magnitude\"][42])) # <class 'numpy.ndarray'>\n",
        "#print(type(df_train[\"magnitude\"][42][42])) # <class 'numpy.float64'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do_0GWJV9CXM",
        "outputId": "b890f934-2628-404e-fa3f-700beb8d566f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ],
      "source": [
        "#print(type(df_test[\"magnitude\"][42])) # <class 'numpy.ndarray'>\n",
        "#print(type(df_test[\"magnitude\"][42][42])) # <class 'numpy.float64'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMey_k0voyDj"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "#df_train = pd.read_csv(\"df_train.csv\")\n",
        "#df_test = pd.read_csv(\"df_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "Zku2NTLp304L",
        "outputId": "d8fc1ed4-c8e6-408d-97e1-6bf822c59172"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_bar_chart(label1, label2, count1, count2):\n",
        "    \"\"\"\n",
        "    Creates a bar chart with two bins based on given labels and counts.\n",
        "\n",
        "    Args:\n",
        "        label1 (str): Label for the first bin.\n",
        "        label2 (str): Label for the second bin.\n",
        "        count1 (int or float): Count for the first bin.\n",
        "        count2 (int or float): Count for the second bin.\n",
        "    \"\"\"\n",
        "    labels = [label1, label2]\n",
        "    counts = [count1, count2]\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(labels, counts, color=['blue', 'orange'])\n",
        "    plt.xlabel('Categories')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.title('Distribution of Classes')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "create_bar_chart(\"Fall instances\", \"non-Fall instances\", 252, 677)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "TwX-kAlxomcu",
        "outputId": "7ac836d1-fd2a-404b-9553-8b856b00084b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m50,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m37,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,665\u001b[0m (350.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,665</span> (350.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,665\u001b[0m (350.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,665</span> (350.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# construct the GRU model\n",
        "\n",
        "model = Sequential([\n",
        "    GRU(128, input_shape=(700, 1), return_sequences=True),  # GRU layer with 128 units\n",
        "    Dropout(0.3),  # Dropout to prevent overfitting\n",
        "    GRU(64, return_sequences=False),  # GRU layer with 64 units\n",
        "    Dropout(0.3),  # Dropout for regularization\n",
        "    Dense(32, activation='relu'),  # Fully connected layer\n",
        "    Dropout(0.2),  # Dropout before output layer\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJvZXoLDpzM7",
        "outputId": "0c606f04-ef88-4ee6-ab2c-1942eceeab74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (696, 700)\n",
            "y_train shape: (696,)\n",
            "x_test shape: (233, 700)\n",
            "y_test shape: (233,)\n"
          ]
        }
      ],
      "source": [
        "# get ready for training\n",
        "\n",
        "def prepare_training_testing_data(df_train, df_test):\n",
        "    \"\"\"\n",
        "    Prepares training and testing data by separating features (X) and labels (Y).\n",
        "\n",
        "    Parameters:\n",
        "        df_train (pd.DataFrame): Training DataFrame with 'magnitude' and 'label' columns.\n",
        "        df_test (pd.DataFrame): Testing DataFrame with 'magnitude' and 'label' columns.\n",
        "\n",
        "    Returns:\n",
        "        x_train, y_train: Features and labels for training.\n",
        "        x_test, y_test: Features and labels for testing.\n",
        "    \"\"\"\n",
        "    # Extract features (X) and labels (Y) for training data\n",
        "    x_train = np.stack(df_train[\"magnitude\"].values)  # Stack magnitudes into a 2D NumPy array\n",
        "    y_train = df_train[\"label\"].values.astype(np.float32)  # Convert labels to a NumPy array of float32\n",
        "\n",
        "    # Extract features (X) and labels (Y) for testing data\n",
        "    x_test = np.stack(df_test[\"magnitude\"].values)  # Stack magnitudes into a 2D NumPy array\n",
        "    y_test = df_test[\"label\"].values.astype(np.float32)  # Convert labels to a NumPy array of float32\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "x_train, y_train, x_test, y_test = prepare_training_testing_data(df_train, df_test)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)  # e.g., (num_samples_train, 700)\n",
        "print(\"y_train shape:\", y_train.shape)  # e.g., (num_samples_train,)\n",
        "\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuaolIXy1xUp"
      },
      "outputs": [],
      "source": [
        "# save splitted ndarrays for easier access\n",
        "np.save('x_train.npy', x_train)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('x_test.npy', x_test)\n",
        "np.save('y_test.npy', y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD7-nDn816SE"
      },
      "outputs": [],
      "source": [
        "# load splitted ndarrays for easier access to do gpu training at the next step\n",
        "#x_train = np.load('x_train.npy', allow_pickle=True)\n",
        "#y_train = np.load('y_train.npy', allow_pickle=True)\n",
        "#x_test = np.load('x_test.npy', allow_pickle=True)\n",
        "#y_test = np.load('y_test.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO9iawwBqqp2",
        "outputId": "a3902eed-6945-4121-ff99-e36d09aa4876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.6586 - loss: 0.6166 - val_accuracy: 0.7214 - val_loss: 0.4583\n",
            "Epoch 2/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7317 - loss: 0.5022 - val_accuracy: 0.7214 - val_loss: 0.4533\n",
            "Epoch 3/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7075 - loss: 0.4878 - val_accuracy: 0.7214 - val_loss: 0.4196\n",
            "Epoch 4/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6591 - loss: 0.4937 - val_accuracy: 0.7214 - val_loss: 0.4158\n",
            "Epoch 5/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7213 - loss: 0.4574 - val_accuracy: 0.7214 - val_loss: 0.4045\n",
            "Epoch 6/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.4418 - val_accuracy: 0.7214 - val_loss: 0.3949\n",
            "Epoch 7/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7365 - loss: 0.4360 - val_accuracy: 0.7357 - val_loss: 0.3809\n",
            "Epoch 8/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7257 - loss: 0.4356 - val_accuracy: 0.7857 - val_loss: 0.3809\n",
            "Epoch 9/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7824 - loss: 0.4306 - val_accuracy: 0.7571 - val_loss: 0.3880\n",
            "Epoch 10/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7771 - loss: 0.4446 - val_accuracy: 0.7500 - val_loss: 0.3763\n",
            "Epoch 11/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7548 - loss: 0.4185 - val_accuracy: 0.7857 - val_loss: 0.3739\n",
            "Epoch 12/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7740 - loss: 0.4300 - val_accuracy: 0.7643 - val_loss: 0.3982\n",
            "Epoch 13/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7740 - loss: 0.4332 - val_accuracy: 0.7571 - val_loss: 0.3895\n",
            "Epoch 14/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7601 - loss: 0.4291 - val_accuracy: 0.7714 - val_loss: 0.3807\n",
            "Epoch 15/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8107 - loss: 0.4050 - val_accuracy: 0.7714 - val_loss: 0.3714\n",
            "Epoch 16/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7542 - loss: 0.4047 - val_accuracy: 0.8000 - val_loss: 0.3752\n",
            "Epoch 17/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8020 - loss: 0.4234 - val_accuracy: 0.8000 - val_loss: 0.3592\n",
            "Epoch 18/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8068 - loss: 0.4255 - val_accuracy: 0.7929 - val_loss: 0.3999\n",
            "Epoch 19/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8116 - loss: 0.3983 - val_accuracy: 0.8143 - val_loss: 0.3510\n",
            "Epoch 20/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8314 - loss: 0.4121 - val_accuracy: 0.8214 - val_loss: 0.3535\n",
            "Epoch 21/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8120 - loss: 0.4027 - val_accuracy: 0.7929 - val_loss: 0.3549\n",
            "Epoch 22/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8453 - loss: 0.3857 - val_accuracy: 0.8571 - val_loss: 0.3413\n",
            "Epoch 23/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8158 - loss: 0.4025 - val_accuracy: 0.8429 - val_loss: 0.3541\n",
            "Epoch 24/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8508 - loss: 0.3467 - val_accuracy: 0.7714 - val_loss: 0.4182\n",
            "Epoch 25/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7158 - loss: 0.4816 - val_accuracy: 0.7643 - val_loss: 0.3802\n",
            "Epoch 26/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7097 - loss: 0.4140 - val_accuracy: 0.7643 - val_loss: 0.3715\n",
            "Epoch 27/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7158 - loss: 0.4200 - val_accuracy: 0.7714 - val_loss: 0.3725\n",
            "Epoch 28/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7752 - loss: 0.4111 - val_accuracy: 0.7786 - val_loss: 0.3713\n",
            "Epoch 29/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7333 - loss: 0.4452 - val_accuracy: 0.7786 - val_loss: 0.3723\n",
            "Epoch 30/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7678 - loss: 0.3972 - val_accuracy: 0.7643 - val_loss: 0.3779\n",
            "Epoch 31/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.7467 - loss: 0.4648 - val_accuracy: 0.7714 - val_loss: 0.3702\n",
            "Epoch 32/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7589 - loss: 0.4074 - val_accuracy: 0.7714 - val_loss: 0.3635\n",
            "Epoch 33/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7697 - loss: 0.4004 - val_accuracy: 0.8357 - val_loss: 0.3612\n",
            "Epoch 34/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7909 - loss: 0.3984 - val_accuracy: 0.8286 - val_loss: 0.3522\n",
            "Epoch 35/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8027 - loss: 0.3664 - val_accuracy: 0.8071 - val_loss: 0.3402\n",
            "Epoch 36/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8343 - loss: 0.3612 - val_accuracy: 0.8571 - val_loss: 0.3408\n",
            "Epoch 37/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8521 - loss: 0.3457 - val_accuracy: 0.8000 - val_loss: 0.3578\n",
            "Epoch 38/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8107 - loss: 0.3609 - val_accuracy: 0.8500 - val_loss: 0.3341\n",
            "Epoch 39/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8669 - loss: 0.3321 - val_accuracy: 0.8143 - val_loss: 0.3414\n",
            "Epoch 40/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8976 - loss: 0.2664 - val_accuracy: 0.9000 - val_loss: 0.2483\n",
            "Epoch 41/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9336 - loss: 0.2053 - val_accuracy: 0.9643 - val_loss: 0.1172\n",
            "Epoch 42/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9463 - loss: 0.1652 - val_accuracy: 0.9643 - val_loss: 0.1101\n",
            "Epoch 43/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9728 - loss: 0.1077 - val_accuracy: 0.9929 - val_loss: 0.0476\n",
            "Epoch 44/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9825 - loss: 0.0571 - val_accuracy: 0.9714 - val_loss: 0.0780\n",
            "Epoch 45/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9639 - loss: 0.1446 - val_accuracy: 0.9786 - val_loss: 0.0603\n",
            "Epoch 46/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9830 - loss: 0.0623 - val_accuracy: 0.9929 - val_loss: 0.0369\n",
            "Epoch 47/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9860 - loss: 0.0603 - val_accuracy: 0.9857 - val_loss: 0.0570\n",
            "Epoch 48/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9703 - loss: 0.0971 - val_accuracy: 0.9929 - val_loss: 0.0315\n",
            "Epoch 49/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9879 - loss: 0.0407 - val_accuracy: 0.9786 - val_loss: 0.0613\n",
            "Epoch 50/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9823 - loss: 0.0676 - val_accuracy: 0.9000 - val_loss: 0.2980\n",
            "Epoch 51/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9506 - loss: 0.1537 - val_accuracy: 0.9929 - val_loss: 0.0359\n",
            "Epoch 52/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9850 - loss: 0.0438 - val_accuracy: 0.9786 - val_loss: 0.0413\n",
            "Epoch 53/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9867 - loss: 0.0459 - val_accuracy: 0.9786 - val_loss: 0.0677\n",
            "Epoch 54/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9797 - loss: 0.0689 - val_accuracy: 0.9857 - val_loss: 0.0379\n",
            "Epoch 55/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9888 - loss: 0.0391 - val_accuracy: 0.9714 - val_loss: 0.0626\n",
            "Epoch 56/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9910 - loss: 0.0418 - val_accuracy: 0.9714 - val_loss: 0.0811\n",
            "Epoch 57/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9951 - loss: 0.0313 - val_accuracy: 0.9714 - val_loss: 0.1040\n",
            "Epoch 58/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9944 - loss: 0.0282 - val_accuracy: 0.9786 - val_loss: 0.0575\n",
            "Epoch 59/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9844 - loss: 0.0450 - val_accuracy: 0.9857 - val_loss: 0.0395\n",
            "Epoch 60/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9885 - loss: 0.0311 - val_accuracy: 0.9714 - val_loss: 0.0311\n",
            "Epoch 61/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9893 - loss: 0.0551 - val_accuracy: 0.9857 - val_loss: 0.0413\n",
            "Epoch 62/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9833 - loss: 0.0535 - val_accuracy: 0.9786 - val_loss: 0.0482\n",
            "Epoch 63/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9942 - loss: 0.0303 - val_accuracy: 0.9929 - val_loss: 0.0223\n",
            "Epoch 64/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9961 - loss: 0.0183 - val_accuracy: 0.9929 - val_loss: 0.0323\n",
            "Epoch 65/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9859 - loss: 0.0351 - val_accuracy: 0.9929 - val_loss: 0.0299\n",
            "Epoch 66/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9874 - loss: 0.0211 - val_accuracy: 0.9857 - val_loss: 0.0347\n",
            "Epoch 67/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9916 - loss: 0.0184 - val_accuracy: 0.9857 - val_loss: 0.0317\n",
            "Epoch 68/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9992 - loss: 0.0089 - val_accuracy: 0.9857 - val_loss: 0.0430\n",
            "Epoch 69/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9896 - loss: 0.0307 - val_accuracy: 0.9786 - val_loss: 0.0521\n",
            "Epoch 70/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9871 - loss: 0.0323 - val_accuracy: 0.9857 - val_loss: 0.0512\n",
            "Epoch 71/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9861 - loss: 0.0503 - val_accuracy: 0.9786 - val_loss: 0.0556\n",
            "Epoch 72/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9940 - loss: 0.0216 - val_accuracy: 0.9929 - val_loss: 0.0263\n",
            "Epoch 73/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9998 - loss: 0.0128 - val_accuracy: 0.9786 - val_loss: 0.0356\n",
            "Epoch 74/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9939 - loss: 0.0198 - val_accuracy: 0.9929 - val_loss: 0.0245\n",
            "Epoch 75/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9897 - loss: 0.0252 - val_accuracy: 0.9786 - val_loss: 0.0617\n",
            "Epoch 76/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9913 - loss: 0.0271 - val_accuracy: 0.9714 - val_loss: 0.0764\n",
            "Epoch 77/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9903 - loss: 0.0255 - val_accuracy: 0.9857 - val_loss: 0.0687\n",
            "Epoch 78/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.9571 - val_loss: 0.0825\n",
            "Epoch 79/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9929 - val_loss: 0.0506\n",
            "Epoch 80/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9889 - loss: 0.0167 - val_accuracy: 0.9786 - val_loss: 0.0592\n",
            "Epoch 81/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.9857 - val_loss: 0.0531\n",
            "Epoch 82/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9930 - loss: 0.0090 - val_accuracy: 0.9857 - val_loss: 0.0377\n",
            "Epoch 83/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9953 - loss: 0.0147 - val_accuracy: 0.9429 - val_loss: 0.1359\n",
            "Epoch 84/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9885 - loss: 0.0513 - val_accuracy: 0.9857 - val_loss: 0.0305\n",
            "Epoch 85/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.9961 - loss: 0.0153 - val_accuracy: 0.9857 - val_loss: 0.0344\n",
            "Epoch 86/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9974 - loss: 0.0128 - val_accuracy: 0.9857 - val_loss: 0.0282\n",
            "Epoch 87/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9997 - loss: 0.0062 - val_accuracy: 0.9857 - val_loss: 0.0410\n",
            "Epoch 88/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9990 - loss: 0.0095 - val_accuracy: 0.9929 - val_loss: 0.0284\n",
            "Epoch 89/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9986 - loss: 0.0064 - val_accuracy: 0.9571 - val_loss: 0.0762\n",
            "Epoch 90/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9862 - loss: 0.0175 - val_accuracy: 0.9643 - val_loss: 0.1056\n",
            "Epoch 91/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9908 - loss: 0.0222 - val_accuracy: 0.9857 - val_loss: 0.0478\n",
            "Epoch 92/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9786 - val_loss: 0.0591\n",
            "Epoch 93/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9857 - val_loss: 0.0621\n",
            "Epoch 94/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9786 - val_loss: 0.0613\n",
            "Epoch 95/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9929 - val_loss: 0.0597\n",
            "Epoch 96/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9714 - val_loss: 0.0854\n",
            "Epoch 97/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9929 - val_loss: 0.0625\n",
            "Epoch 98/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 6.9216e-04 - val_accuracy: 0.9929 - val_loss: 0.0631\n",
            "Epoch 99/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 7.5883e-04 - val_accuracy: 0.9857 - val_loss: 0.0657\n",
            "Epoch 100/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9786 - val_loss: 0.0655\n",
            "Epoch 101/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.7484e-04 - val_accuracy: 0.9857 - val_loss: 0.0643\n",
            "Epoch 102/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 7.9173e-04 - val_accuracy: 0.9929 - val_loss: 0.0674\n",
            "Epoch 103/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.7605e-04 - val_accuracy: 0.9857 - val_loss: 0.0692\n",
            "Epoch 104/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.8256e-04 - val_accuracy: 0.9786 - val_loss: 0.0706\n",
            "Epoch 105/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.9410e-04 - val_accuracy: 0.9786 - val_loss: 0.0716\n",
            "Epoch 106/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.0370e-04 - val_accuracy: 0.9786 - val_loss: 0.0730\n",
            "Epoch 107/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.2121e-04 - val_accuracy: 0.9857 - val_loss: 0.0744\n",
            "Epoch 108/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.9507e-04 - val_accuracy: 0.9857 - val_loss: 0.0728\n",
            "Epoch 109/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.5953e-04 - val_accuracy: 0.9929 - val_loss: 0.0710\n",
            "Epoch 110/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.9511e-04 - val_accuracy: 0.9929 - val_loss: 0.0704\n",
            "Epoch 111/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.9204e-04 - val_accuracy: 0.9929 - val_loss: 0.0706\n",
            "Epoch 112/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.0076e-04 - val_accuracy: 0.9929 - val_loss: 0.0717\n",
            "Epoch 113/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.8871e-04 - val_accuracy: 0.9857 - val_loss: 0.0732\n",
            "Epoch 114/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.3615e-04 - val_accuracy: 0.9857 - val_loss: 0.0742\n",
            "Epoch 115/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.8574e-04 - val_accuracy: 0.9857 - val_loss: 0.0746\n",
            "Epoch 116/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 2.4150e-04 - val_accuracy: 0.9857 - val_loss: 0.0741\n",
            "Epoch 117/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.2410e-04 - val_accuracy: 0.9857 - val_loss: 0.0741\n",
            "Epoch 118/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.6978e-04 - val_accuracy: 0.9857 - val_loss: 0.0742\n",
            "Epoch 119/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.1118e-04 - val_accuracy: 0.9857 - val_loss: 0.0753\n",
            "Epoch 120/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.2044e-04 - val_accuracy: 0.9857 - val_loss: 0.0740\n",
            "Epoch 121/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.2312e-04 - val_accuracy: 0.9857 - val_loss: 0.0725\n",
            "Epoch 122/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.2689e-04 - val_accuracy: 0.9929 - val_loss: 0.0697\n",
            "Epoch 123/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.7075e-04 - val_accuracy: 0.9929 - val_loss: 0.0686\n",
            "Epoch 124/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.7569e-04 - val_accuracy: 0.9929 - val_loss: 0.0686\n",
            "Epoch 125/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.5381e-04 - val_accuracy: 0.9929 - val_loss: 0.0694\n",
            "Epoch 126/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.5467e-04 - val_accuracy: 0.9929 - val_loss: 0.0697\n",
            "Epoch 127/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.8303e-04 - val_accuracy: 0.9929 - val_loss: 0.0686\n",
            "Epoch 128/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6327e-04 - val_accuracy: 0.9929 - val_loss: 0.0680\n",
            "Epoch 129/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.1812e-04 - val_accuracy: 0.9929 - val_loss: 0.0681\n",
            "Epoch 130/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 1.6018e-04 - val_accuracy: 0.9857 - val_loss: 0.0691\n",
            "Epoch 131/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.3575e-04 - val_accuracy: 0.9929 - val_loss: 0.0724\n",
            "Epoch 132/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.8284e-04 - val_accuracy: 0.9929 - val_loss: 0.0748\n",
            "Epoch 133/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.2970e-04 - val_accuracy: 0.9929 - val_loss: 0.0745\n",
            "Epoch 134/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.5478e-04 - val_accuracy: 0.9929 - val_loss: 0.0758\n",
            "Epoch 135/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.7740e-04 - val_accuracy: 0.9929 - val_loss: 0.0760\n",
            "Epoch 136/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.1864e-04 - val_accuracy: 0.9929 - val_loss: 0.0733\n",
            "Epoch 137/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.4924e-04 - val_accuracy: 0.9929 - val_loss: 0.0720\n",
            "Epoch 138/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.2751e-04 - val_accuracy: 0.9929 - val_loss: 0.0732\n",
            "Epoch 139/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.3757e-04 - val_accuracy: 0.9929 - val_loss: 0.0728\n",
            "Epoch 140/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.6269e-04 - val_accuracy: 0.9929 - val_loss: 0.0724\n",
            "Epoch 141/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.5987e-04 - val_accuracy: 0.9929 - val_loss: 0.0730\n",
            "Epoch 142/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 7.0531e-05 - val_accuracy: 0.9929 - val_loss: 0.0728\n",
            "Epoch 143/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 1.2840e-04 - val_accuracy: 0.9929 - val_loss: 0.0732\n",
            "Epoch 144/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.5397e-04 - val_accuracy: 0.9929 - val_loss: 0.0737\n",
            "Epoch 145/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.2488e-05 - val_accuracy: 0.9929 - val_loss: 0.0750\n",
            "Epoch 146/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.5355e-04 - val_accuracy: 0.9929 - val_loss: 0.0749\n",
            "Epoch 147/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.8748e-04 - val_accuracy: 0.9929 - val_loss: 0.0750\n",
            "Epoch 148/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.1519e-04 - val_accuracy: 0.9929 - val_loss: 0.0748\n",
            "Epoch 149/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.2264e-05 - val_accuracy: 0.9929 - val_loss: 0.0753\n",
            "Epoch 150/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.5150e-04 - val_accuracy: 0.9929 - val_loss: 0.0767\n",
            "Epoch 151/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.1885e-05 - val_accuracy: 0.9929 - val_loss: 0.0775\n",
            "Epoch 152/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.7811e-04 - val_accuracy: 0.9929 - val_loss: 0.0778\n",
            "Epoch 153/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.1483e-04 - val_accuracy: 0.9929 - val_loss: 0.0784\n",
            "Epoch 154/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.8229e-05 - val_accuracy: 0.9929 - val_loss: 0.0788\n",
            "Epoch 155/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.5558e-05 - val_accuracy: 0.9929 - val_loss: 0.0790\n",
            "Epoch 156/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.9175e-04 - val_accuracy: 0.9929 - val_loss: 0.0804\n",
            "Epoch 157/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7229e-04 - val_accuracy: 0.9857 - val_loss: 0.0815\n",
            "Epoch 158/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.3692e-05 - val_accuracy: 0.9857 - val_loss: 0.0817\n",
            "Epoch 159/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 8.7506e-05 - val_accuracy: 0.9857 - val_loss: 0.0818\n",
            "Epoch 160/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 8.7870e-05 - val_accuracy: 0.9857 - val_loss: 0.0820\n",
            "Epoch 161/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 8.1395e-05 - val_accuracy: 0.9857 - val_loss: 0.0821\n",
            "Epoch 162/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 1.0897e-04 - val_accuracy: 0.9857 - val_loss: 0.0820\n",
            "Epoch 163/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.0538e-04 - val_accuracy: 0.9857 - val_loss: 0.0818\n",
            "Epoch 164/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.1266e-05 - val_accuracy: 0.9857 - val_loss: 0.0819\n",
            "Epoch 165/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.5841e-05 - val_accuracy: 0.9857 - val_loss: 0.0811\n",
            "Epoch 166/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.1296e-04 - val_accuracy: 0.9857 - val_loss: 0.0815\n",
            "Epoch 167/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.3864e-05 - val_accuracy: 0.9857 - val_loss: 0.0814\n",
            "Epoch 168/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4575e-04 - val_accuracy: 0.9857 - val_loss: 0.0833\n",
            "Epoch 169/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.9358e-05 - val_accuracy: 0.9857 - val_loss: 0.0845\n",
            "Epoch 170/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 3.1239e-04 - val_accuracy: 0.9857 - val_loss: 0.0843\n",
            "Epoch 171/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 4.7082e-04 - val_accuracy: 0.9786 - val_loss: 0.1093\n",
            "Epoch 172/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.3812e-05 - val_accuracy: 0.9786 - val_loss: 0.1168\n",
            "Epoch 173/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6554e-04 - val_accuracy: 0.9786 - val_loss: 0.1176\n",
            "Epoch 174/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.5407e-05 - val_accuracy: 0.9786 - val_loss: 0.1093\n",
            "Epoch 175/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 5.3883e-05 - val_accuracy: 0.9857 - val_loss: 0.0973\n",
            "Epoch 176/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 8.4131e-05 - val_accuracy: 0.9857 - val_loss: 0.0963\n",
            "Epoch 177/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.7735e-05 - val_accuracy: 0.9857 - val_loss: 0.0962\n",
            "Epoch 178/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 4.8607e-05 - val_accuracy: 0.9857 - val_loss: 0.0965\n",
            "Epoch 179/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.0871e-04 - val_accuracy: 0.9857 - val_loss: 0.0968\n",
            "Epoch 180/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 9.8307e-05 - val_accuracy: 0.9857 - val_loss: 0.0978\n",
            "Epoch 181/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 7.7214e-05 - val_accuracy: 0.9857 - val_loss: 0.1000\n",
            "Epoch 182/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 4.5071e-05 - val_accuracy: 0.9857 - val_loss: 0.1012\n",
            "Epoch 183/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 9.7322e-05 - val_accuracy: 0.9857 - val_loss: 0.1013\n",
            "Epoch 184/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.0509e-04 - val_accuracy: 0.9857 - val_loss: 0.1011\n",
            "Epoch 185/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 6.6987e-05 - val_accuracy: 0.9857 - val_loss: 0.1009\n",
            "Epoch 186/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.6911e-04 - val_accuracy: 0.9857 - val_loss: 0.1009\n",
            "Epoch 187/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.9413e-05 - val_accuracy: 0.9857 - val_loss: 0.1012\n",
            "Epoch 188/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.8933e-05 - val_accuracy: 0.9857 - val_loss: 0.1021\n",
            "Epoch 189/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.4383e-05 - val_accuracy: 0.9857 - val_loss: 0.1020\n",
            "Epoch 190/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 6.0870e-05 - val_accuracy: 0.9857 - val_loss: 0.1016\n",
            "Epoch 191/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 5.9890e-05 - val_accuracy: 0.9857 - val_loss: 0.1025\n",
            "Epoch 192/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 8.0916e-05 - val_accuracy: 0.9857 - val_loss: 0.1030\n",
            "Epoch 193/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 5.2047e-05 - val_accuracy: 0.9857 - val_loss: 0.1025\n",
            "Epoch 194/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 4.9313e-05 - val_accuracy: 0.9857 - val_loss: 0.1021\n",
            "Epoch 195/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 7.0337e-05 - val_accuracy: 0.9857 - val_loss: 0.1029\n",
            "Epoch 196/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 9.9718e-05 - val_accuracy: 0.9857 - val_loss: 0.1025\n",
            "Epoch 197/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.9093e-05 - val_accuracy: 0.9857 - val_loss: 0.1017\n",
            "Epoch 198/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.8904e-05 - val_accuracy: 0.9857 - val_loss: 0.1019\n",
            "Epoch 199/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.1021\n",
            "Epoch 200/200\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.2474e-05 - val_accuracy: 0.9857 - val_loss: 0.1025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "# training (run imports, model architecture and np.loads if running this on gpu)\n",
        "\n",
        "log_dir = os.path.join(\"logs\", \"fit\", \"run_1\")  # Change \"run_1\" for different training runs\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    verbose=1,\n",
        "    epochs=200,  # Number of epochs can be 20\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,  # Use 20% of training data for validation\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5xWgQ8DA9XB",
        "outputId": "92d5b278-f7bd-4ed1-c95b-052946d97087"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "model.save(\"my_gru_model.weights.h5\")  # Save the model in HDF5 format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx9tvB35ETSy",
        "outputId": "4543a310-a6ef-44f5-8562-95ff281184d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Test Loss: 0.0009883396560326219\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}