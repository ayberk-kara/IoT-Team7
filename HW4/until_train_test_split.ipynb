{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "bunu kullandÄ±k devam edebilirsiniz:\n",
        "\n",
        "https://chatgpt.com/share/67410a77-56bc-8001-8105-c46d14f84456"
      ],
      "metadata": {
        "id": "appCf5wCEo5R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xoajWaM4n3CK",
        "outputId": "0f3303de-893d-4860-eb2a-6691e1e0b193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_room_based_frames(df, rowCountFrame):\n",
        "    \"\"\"\n",
        "    Creates frames from a preprocessed DataFrame based on 'Room' categories.\n",
        "\n",
        "    :param df: Input preprocessed DataFrame.\n",
        "    :param rowCountFrame: Number of rows each frame should contain.\n",
        "    :return: List of frames (DataFrames).\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "\n",
        "    # Group data by 'Room'\n",
        "    grouped = df.groupby('Room')\n",
        "\n",
        "    # Iterate through each group\n",
        "    for room, group in grouped:\n",
        "        # Split group into chunks of rowCountFrame size\n",
        "        for i in range(0, len(group), rowCountFrame):\n",
        "            chunk = group.iloc[i:i+rowCountFrame]\n",
        "            # Ensure the chunk has exactly rowCountFrame rows\n",
        "            if len(chunk) == rowCountFrame:\n",
        "                frames.append(chunk)\n",
        "\n",
        "    print(f\"Total frames created: {len(frames)}\")\n",
        "    return frames\n",
        "\n",
        "\n",
        "def process_dataframe(df):\n",
        "    \"\"\"\n",
        "    Processes the input DataFrame by label encoding specific columns and printing summary information.\n",
        "\n",
        "    :param df: Input DataFrame with concatenated data.\n",
        "    :return: Processed DataFrame with label-encoded columns.\n",
        "    \"\"\"\n",
        "    # Print the number of rows in the input DataFrame\n",
        "    print(f\"Number of rows in the input DataFrame: {len(df)}\")\n",
        "\n",
        "    # Initialize a dictionary to store unique value counts\n",
        "    unique_values = {}\n",
        "\n",
        "    # Columns to label encode\n",
        "    df = df.drop([\"ESSID\",\"Frequency\",\"Bit Rate\",\"Timestamp\"],axis=\"columns\")\n",
        "\n",
        "    columns_to_encode = [\"Room\", \"Address\", \"ESSID\", \"Frequency\", \"Bit Rate\"]\n",
        "    label_encoders = {}\n",
        "\n",
        "    # Label encode each specified column and count unique values\n",
        "    for column in columns_to_encode:\n",
        "        if column in df.columns:\n",
        "            le = LabelEncoder()\n",
        "            df[column] = le.fit_transform(df[column].astype(str))  # Convert to string for encoding\n",
        "            label_encoders[column] = le\n",
        "            unique_values[column] = len(le.classes_)  # Count unique classes\n",
        "        else:\n",
        "            print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
        "    if \"Signal Level\" in df.columns:\n",
        "        df[\"Signal Level\"] = 1 - (df[\"Signal Level\"] * -0.01)\n",
        "\n",
        "\n",
        "    # Print the number of unique values in each column\n",
        "    for column, count in unique_values.items():\n",
        "        print(f\"Column '{column}' has {count} unique values.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hoq6erFvoBLG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty DataFrame to hold all data\n",
        "final_dataframe = pd.DataFrame()\n",
        "\n",
        "# Directory containing the CSV files\n",
        "directory_path = '.'  # Update with the path to your directory\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for file in os.listdir(directory_path):\n",
        "    if file.endswith('.csv') and file != \"concatenated_dataframe.csv\":\n",
        "        file_path = os.path.join(directory_path, file)\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "\n",
        "        # Read the CSV into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Append the processed DataFrame to the final DataFrame\n",
        "        final_dataframe = pd.concat([final_dataframe, df], ignore_index=True)\n",
        "\n",
        "# Print summary of the final DataFrame\n",
        "print(f\"Final DataFrame shape: {final_dataframe.shape}\")\n",
        "# save final_dataframe as csv\n",
        "processed_df = process_dataframe(final_dataframe)\n",
        "processed_df.to_csv('dataset.csv', index=False)\n",
        "\n",
        "\n",
        "rowCountFrame = 10  # Set the desired frame size\n",
        "frames = create_room_based_frames(processed_df, rowCountFrame)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xab4JROqZBa",
        "outputId": "2af7e04e-5ad4-451f-e25a-d214bf6ce6aa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: ./wifi_scan_L035_1732312703.csv\n",
            "Processing file: ./wifi_scan_bathroom_1732311595.csv\n",
            "Processing file: ./wifi_scan_L056_1732304554.csv\n",
            "Processing file: ./wifi_scan_L030_1732309218.csv\n",
            "Processing file: ./wifi_scan_L048_1732307002.csv\n",
            "Processing file: ./wifi_scan_L027_1732312244.csv\n",
            "Processing file: ./wifi_scan_L047_1732307455.csv\n",
            "Processing file: ./wifi_scan_L045_1732308641.csv\n",
            "Processing file: ./wifi_scan_corridoor1_1732306010.csv\n",
            "Processing file: ./wifi_scan_L029_1732310213.csv\n",
            "Processing file: ./wifi_scan_L055_1732305415.csv\n",
            "Processing file: ./wifi_scan_corridoor2_1732310902.csv\n",
            "Final DataFrame shape: (20608, 7)\n",
            "Number of rows in the input DataFrame: 20608\n",
            "Warning: Column 'ESSID' not found in the DataFrame.\n",
            "Warning: Column 'Frequency' not found in the DataFrame.\n",
            "Warning: Column 'Bit Rate' not found in the DataFrame.\n",
            "Column 'Room' has 12 unique values.\n",
            "Column 'Address' has 95 unique values.\n",
            "Total frames created: 2056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Shuffle the frames\n",
        "random.shuffle(frames)\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_frames, test_frames = train_test_split(frames, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split training frames into training and validation sets\n",
        "train_frames, val_frames = train_test_split(train_frames, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to extract X and Y from frames\n",
        "def extract_X_Y(frames):\n",
        "    \"\"\"\n",
        "    Extracts X (features) and Y (labels) from a list of frames.\n",
        "\n",
        "    :param frames: List of DataFrames (frames).\n",
        "    :return: X (features as a DataFrame), Y (labels as a Series).\n",
        "    \"\"\"\n",
        "    X_list = []\n",
        "    Y_list = []\n",
        "\n",
        "    for frame in frames:\n",
        "        X = frame.drop(columns=[\"Room\"])  # Drop the 'Room' column for features\n",
        "        Y = frame[\"Room\"]  # Use 'Room' as labels\n",
        "        X_list.append(X)\n",
        "        Y_list.append(Y)\n",
        "\n",
        "    # Concatenate all frames into a single DataFrame/Series\n",
        "    X = pd.concat(X_list, ignore_index=True)\n",
        "    Y = pd.concat(Y_list, ignore_index=True)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# Extract X and Y for train, validation, and test sets\n",
        "X_train, Y_train = extract_X_Y(train_frames)\n",
        "X_val, Y_val = extract_X_Y(val_frames)\n",
        "X_test, Y_test = extract_X_Y(test_frames)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Training set: X={X_train.shape}, Y={Y_train.shape}\")\n",
        "print(f\"Validation set: X={X_val.shape}, Y={Y_val.shape}\")\n",
        "print(f\"Testing set: X={X_test.shape}, Y={Y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBpXmC6l_QGW",
        "outputId": "823dcd2a-6ce8-4ce2-92ce-fab43cd6683d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: X=(13150, 2), Y=(13150,)\n",
            "Validation set: X=(3290, 2), Y=(3290,)\n",
            "Testing set: X=(4120, 2), Y=(4120,)\n"
          ]
        }
      ]
    }
  ]
}